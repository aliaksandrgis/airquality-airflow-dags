# Airflow runs as uid (default 50000) for volume permissions.
AIRFLOW_UID=50000

# Required for DockerOperator (so Airflow can talk to host Docker via /var/run/docker.sock).
# Find it on the VPS with: `getent group docker | cut -d: -f3`
DOCKER_GID=999

# Image used by Airflow tasks (built by `docker-compose build producer`).
AIRQUALITY_PRODUCER_IMAGE=vps_producer:latest

# Keep only N days of Airflow task logs (cleaned by `airquality_housekeeping` DAG).
AIRFLOW_TASK_LOG_RETENTION_DAYS=14

# Avoid automatic scheduling during migration.
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True

# Generate once and keep stable across restarts.
# FERNET key must be urlsafe base64 (32 bytes):
#   python3 - <<'PY'
#   import base64,os; print(base64.urlsafe_b64encode(os.urandom(32)).decode())
#   PY
AIRFLOW__CORE__FERNET_KEY=generate_me

# Any random string is fine:
#   python3 -c "import secrets; print(secrets.token_hex(16))"
AIRFLOW__WEBSERVER__SECRET_KEY=generate_me_too

# Admin user created by `airflow-init`
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_EMAIL=admin@example.com
